{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Comparison\n",
    "In this notebook, we retrain the random forest classifier and LSTM model for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare data and split into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "data = pd.read_csv('combined_feature_vectors.csv')\n",
    "\n",
    "# Prepare features and labels\n",
    "X = data.drop('Label', axis=1)\n",
    "y = data['Label']\n",
    "\n",
    "# Scale the features\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# For LSTM, reshape data to [samples, time steps, features]\n",
    "X_scaled_lstm = X_scaled.reshape(X_scaled.shape[0], 1, X_scaled.shape[1])\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train_rf, X_test_rf, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "X_train_lstm, X_test_lstm = X_train_rf.reshape(X_train_rf.shape[0], 1, X_train_rf.shape[1]), X_test_rf.reshape(X_test_rf.shape[0], 1, X_test_rf.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Random Forest and LSTM Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch 1/30\n",
      "2250/2250 [==============================] - 16s 6ms/step - loss: 0.4827 - accuracy: 0.7345 - val_loss: 0.3061 - val_accuracy: 0.8835\n",
      "Epoch 2/30\n",
      "2250/2250 [==============================] - 14s 6ms/step - loss: 0.2571 - accuracy: 0.8920 - val_loss: 0.2313 - val_accuracy: 0.9007\n",
      "Epoch 3/30\n",
      "2250/2250 [==============================] - 13s 6ms/step - loss: 0.2181 - accuracy: 0.9051 - val_loss: 0.2113 - val_accuracy: 0.9140\n",
      "Epoch 4/30\n",
      "2250/2250 [==============================] - 13s 6ms/step - loss: 0.2049 - accuracy: 0.9111 - val_loss: 0.2016 - val_accuracy: 0.9109\n",
      "Epoch 5/30\n",
      "2250/2250 [==============================] - 13s 6ms/step - loss: 0.1969 - accuracy: 0.9142 - val_loss: 0.1942 - val_accuracy: 0.9135\n",
      "Epoch 6/30\n",
      "2250/2250 [==============================] - 14s 6ms/step - loss: 0.1898 - accuracy: 0.9163 - val_loss: 0.1884 - val_accuracy: 0.9177\n",
      "Epoch 7/30\n",
      "2250/2250 [==============================] - 14s 6ms/step - loss: 0.1836 - accuracy: 0.9187 - val_loss: 0.1803 - val_accuracy: 0.9211\n",
      "Epoch 8/30\n",
      "2250/2250 [==============================] - 13s 6ms/step - loss: 0.1783 - accuracy: 0.9206 - val_loss: 0.1749 - val_accuracy: 0.9246\n",
      "Epoch 9/30\n",
      "2250/2250 [==============================] - 14s 6ms/step - loss: 0.1731 - accuracy: 0.9223 - val_loss: 0.1702 - val_accuracy: 0.9274\n",
      "Epoch 10/30\n",
      "2250/2250 [==============================] - 14s 6ms/step - loss: 0.1687 - accuracy: 0.9245 - val_loss: 0.1661 - val_accuracy: 0.9256\n",
      "Epoch 11/30\n",
      "2250/2250 [==============================] - 14s 6ms/step - loss: 0.1644 - accuracy: 0.9252 - val_loss: 0.1619 - val_accuracy: 0.9284\n",
      "Epoch 12/30\n",
      "2250/2250 [==============================] - 13s 6ms/step - loss: 0.1606 - accuracy: 0.9276 - val_loss: 0.1589 - val_accuracy: 0.9337\n",
      "Epoch 13/30\n",
      "2250/2250 [==============================] - 14s 6ms/step - loss: 0.1569 - accuracy: 0.9293 - val_loss: 0.1567 - val_accuracy: 0.9245\n",
      "Epoch 14/30\n",
      "1365/2250 [=================>............] - ETA: 5s - loss: 0.1549 - accuracy: 0.9287"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Random Forest Model\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_classifier.fit(X_train_rf, y_train)\n",
    "\n",
    "# Define the early stopping callback\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',   # Monitor the validation loss\n",
    "    min_delta=0.001,      # Minimum change to qualify as an improvement\n",
    "    patience=10,          # Stop after 10 epochs without improvement\n",
    "    restore_best_weights=True  # Restore the best weights found during training\n",
    ")\n",
    "\n",
    "# LSTM Model setup\n",
    "model = Sequential([\n",
    "    LSTM(50, activation='relu', input_shape=(1, X_train_lstm.shape[2])),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.fit(X_train_lstm, y_train, epochs=30, batch_size=32, validation_split=0.1, callbacks=[early_stopping])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict Probabilities and Compute AUC/ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 1s 1ms/step\n",
      "Random Forest AUC: 1.000\n",
      "LSTM AUC: 0.989\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Predict probabilities\n",
    "rf_probs = rf_classifier.predict_proba(X_test_rf)[:, 1]\n",
    "lstm_probs = model.predict(X_test_lstm).flatten()  # Flatten is used as model.predict returns a 2D array\n",
    "\n",
    "# Calculate ROC curve and AUC\n",
    "rf_fpr, rf_tpr, _ = roc_curve(y_test, rf_probs)\n",
    "rf_auc = auc(rf_fpr, rf_tpr)\n",
    "lstm_fpr, lstm_tpr, _ = roc_curve(y_test, lstm_probs)\n",
    "lstm_auc = auc(lstm_fpr, lstm_tpr)\n",
    "\n",
    "# Display AUC\n",
    "print(\"Random Forest AUC: {:.3f}\".format(rf_auc))\n",
    "print(\"LSTM AUC: {:.3f}\".format(lstm_auc))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot ROC Curves for Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 8))\n",
    "plt.plot(rf_fpr, rf_tpr, label='Random Forest (AUC = {:.3f})'.format(rf_auc))\n",
    "plt.plot(lstm_fpr, lstm_tpr, label='LSTM (AUC = {:.3f})'.format(lstm_auc))\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curves Comparison')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
